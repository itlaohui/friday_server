spring:
  datasource:
    url: jdbc:mysql://182.254.220.232/firday
    username: firday
    password: xFT2cCisydk4N8R2
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
  redis:
    host: localhost
    port: 6379
    timeout: 1000
    jedis:
      pool:
        max-active: 200
        max-idle: 10
        max-wait: -1
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: friday-consumer
      enable-auto-commit: true
      auto-commit-interval: 100ms
      properties:
        session.timeout.ms: 15000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
    producer:
      retries: 0 #若设置大于0的值，客户端会将发送失败的记录重新发送
      batch-size: 16384 #当将多个记录被发送到同一个分区时， Producer 将尝试将记录组合到更少的请求中。这有助于提升客户端和服务器端的性能。这个配置控制一个批次的默认大小（以字节为单位）。16384是缺省的配置
      buffer-memory: 33554432 #Producer 用来缓冲等待被发送到服务器的记录的总字节数，33554432是缺省配置
      key-serializer: org.apache.kafka.common.serialization.StringSerializer #关键字的序列化类
      value-serializer: org.apache.kafka.common.serialization.StringSerializer #值的序列化类

#  activemq:
#    broker-url: tcp://127.0.0.1:61616
#    user: laohui
#    password: laohui
#    packages:
#      trust-all: true
mybatis-plus:
  mapper-locations: classpath:net/laohui/mapper/*Mapper.xml
  configuration:
    map-underscore-to-camel-case: false
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

server:
  servlet:
    encoding:
      force: true
  port: 801

shiro:
  web:
    enabled: true
#  enabled: true
#  loginUrl: /login
#  sessionManager:
#    sessionIdCookieEnabled: true
#    sessionIdUrlRewritingEnabled: true

